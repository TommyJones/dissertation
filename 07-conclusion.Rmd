# Conclusion

I dream of a world where we can measure the ideas and narratives that drive human behavior with the same rigor we use to measure the economy, human health, and other societal markers based on structured numeric data. To achieve this dream, we need better statistical theory for working with language as data---which I refer to as Natural Language Statistics---and intuitive tooling for language analysis. In this dissertation, I have taken small but substantive steps to address both needs. I have argued that LDA is an appealing model for Natural Language Statistics. It models a data generating process which may be linked to the empirical laws of language. This property makes LDA, and related models, candidates for helping to develop a more robust statistical theory for modeling language. Moreover, LDA embeds collections of word occurrences into a probability space, ideal for quantifying uncertainty and leaning on probability theory to analyze results. 

In this dissertation I have linked the LDA-DGP to Zipf's and Heaps's laws, enabling simulation studies of LDA to incorporate fundamental properties of human language, and making them more principled. I have employed such simulations to produce a pilot study of the effects of misspecifying hyper parameters when fitting LDA models. I have derived a generalization of the coefficient of determination, allowing it to be extended to topic models. The coefficient of determination---$R^2$---is intuitive and in wide use for linear statistical models, thus making interpreting LDA more accessible. I have extended LDA to tLDA, a model enabling the use of LDA to develop foundation models and fine tune them in a way that preserves the Markov property. And I have written and released _tidylda_ a package for the R programming language. _tidylda_ implements much of the research in this dissertation and follows conventions of R's "tidyverse" system of packages, known for their user friendliness, thus making topic modeling more accessible to a wider audience of practitioners. And yet, while the work in this dissertation has taken meaningful steps towards making use of LDA more rigorous, much more remains to be done. 

Simulations could be more realistic, especially in incorporating stop words, accounting for correlations in a corpus, or changing topics over time. I used the standard definition of Zipf's law for this dissertation, but the more general Zipf-Mandlebrodt law may better lead to better simulations of corpora with stop words removed. Adopting a probabilistic definition of the Zipf-Mandlebrodt law may offer ultimate flexibility and tie the LDA-DGP further into an end-to-end statistical theory of language data. 

The simulations in this dissertation were of static corpora with no intra-context correlations. Might we extend simulations to account for such correlations as the CTM and STM models do? Could we extend simulations to account for changes over time? I would hypothesize that simulations incorporating these would either better account for patterns seen in real-world data or they would further justify using the simpler approach as done here. 

Researchers still need better guidance for selecting hyper parameters when fitting LDA models. This research shows that $\boldsymbol\eta$ is more important than conventionally understood and that $K$ is as important as conventional wisdom suggests. Even so, it was not sufficient to find a protocol or concrete diagnostics about model specification. As future work, I would explore various protocols to find support for their use or evidence that they do not help (or that they hurt). For example, it is common in the literature to build models for many different values of $K$ and choose one that maximizes a statistic of interest. This is computationally infeasible for a large corpus. Yet anecdotally, fitting a model with too many topics and then pruning "junk" topics (those with low prevalence or coherence etc.) are then discarded. Might there be validity to this approach? Could partial $R^2$---as shown in Chapter 4---inform selecting junk topics? Another example: MALLET uses a method for optimizing $\boldsymbol\alpha$ during fitting. Does this method often find the correct $\boldsymbol\alpha$ on synthetic data? Might setting a non-informative $\boldsymbol\alpha$ be beneficial? We are yet a long way from having guidance for LDA that is of the quality for fitting linear models.

tLDA is a flexible and analyzable method for pre-train/fine tune transfer learning. Yet to scale to the corpora used to train deep learning transformers, the Gibbs algorithm is insufficient. Extending tLDA to algorithms like WarpLDA [@chen2015warplda] and perhaps implementing it on a GPU would help compare the tradeoffs of using probabilistic topic models versus black box transformers. Yet until we can fit LDA models of comparable scale, any benefits are hypothetical.

In this dissertation, I demonstrated tLDA on a time series use case. But other use cases are possible and should be explored. Most obviously, one should build foundation models and compare results to transformers where applicable, perhaps using LDA to vectorize text before performing a downstream task. This requires an algorithm that scales, as discussed above. Also, tLDA can enable a "differences" analysis comparing groups, analogous to estimating treatment effects. Such analyses might be applied to researching the efficacy of marketing or the effects of exposure to propaganda.

_tidylda_ implements the methods demonstrated in this dissertation. It is available for anyone who wishes to use it. Yet _tidylda_ could still benefit from user feedback. An obvious place to start would be to implment a more scaleable algorithm, as above. Another obvious improvement would be to develop a method for expert-seeded topics using tLDA. Finally, as we get better guidance on how to set LDA's hyper parameters, _tidylda_ would modify its defaults so that a user has a good shot of a reasonable model with minimum effort.

A work is never finished, it's just taken away. In spite of the need for more research, the research contained in this dissertation has taken a tiny step towards making LDA better for Natural Language Statistics and improving our understanding of how to measure ideas and narratives with statistical rigour.



