# Fine Tuning Latent Dirichlet Allocation for Transfer Learning {#transfer}
As stated in Section 1, properties of language make the fine tuning paradigm of transfer learning attractive for statistical analyses of corpora. The pervasiveness of power laws in language---the most famous example of which is Zipf's law [@zipf1949]---mean that we can expect just about any corpus of language to not contain information relevant to the analysis. (i.e., Linguistic information necessary for understanding the corpus of study would be contained in a super set of language around---but not contained in---said corpus.) Intuitively, humans approach corpus analytics in a way that on its surface appears consistent with fine tuning transfer learning. Humans have general competence in a language before consulting a corpus to learn a new subject---or even just to have human analysis of the corpus. Also as stated in Section 1, LDA has attractive properties as a model for statistical analyses of corpora. Its very nature allows us to use probability theory to guide model specification and quantify uncertainty around claims made with the model. 

This chapter introduces _tLDA_, short for transfer-LDA. tLDA enables use cases for fine-tuning from a base model with a single incremental update (i.e., "fine tuning") or with many incremental updates---e.g., on-line learning, possibly in a time-series context---using Latent Dirichlet Allocation. tLDA uses collapsed Gibbs sampling [@griffiths2004scientific] but its methods should extend to other MCMC methods [@yao2009streaming][@lightlda][@yahoolda][@chen2015warplda]. tLDA is available for the R language for statistical computing [@rlang] in the _tidylda_ package [@tidylda].

## Related Work

Work on transfer learning with LDA and other probabilistic topic models falls into three categories. The first category contains topic models that explicitly model a topic's evolution over time [@blei2006dtm][@wang2012dynamic][@tmlda]. These models differ from true transfer learning in that time is explicitly part of the model, rather than being updated post-hoc. The second category contains models that allow external information to guide the development of topics. External information may be in the form of supervised outcomes [@mcauliffe2007supervised] [@ramage2009labled] [@andrzejewski2009latent], seeded by model structure [@jagarlamudi2012transfer], seeded in the prior [@andrzejewski2009], or constructed interactively with subject matter experts [@hu2014interactive]. The third category contains models designed for incremental and on-line learning [@alsumait2008][@hoffman2010online][@rollinglda].

## Contribution
tLDA is a model for updating topics in an existing model with new data, enabling incremental updates and time-series use cases. tLDA has three characteristics differentiating it from previous work:

1. Flexibility - Most prior work can only address use cases from one of the above categories. In theory, tLDA can address all three. However, exploring use of tLDA to encode expert input into the $\boldsymbol\eta$ prior is left to future work.
2. Tunability - tLDA introduces only a single new tuning parameter, $a$. Its use is intuitive, balancing the ratio of tokens in $\boldsymbol{X}^{(t)}$ to the base model's data, $\boldsymbol{X}^{(t-1)}$. 
3. Analytical - tLDA allows data sets and model updates to be chained together preserving the Markov property, enabling analytical study through incremental updates.

## tLDA

### The Model

Formally, tLDA can be stated as

\begin{align}
z_{d_{n}}|\boldsymbol\theta_d &\sim 
\text{Categorical}(\boldsymbol\theta_d)\\
w_{d_{n}}|z_{k},\boldsymbol\beta_k^{(t)} &\sim
\text{Categorical}(\boldsymbol\beta_k^{(t)}) \\
\boldsymbol\theta_d &\sim
\text{Dirichlet}(\boldsymbol\alpha_d)\\
\boldsymbol\beta_k^{(t)} &\sim
\text{Dirichlet}(\omega_k^{(t)} \cdot \mathbb{E}\left[\boldsymbol\beta_k^{(t-1)}\right])
\end{align}

The above indicates that tLDA places a matrix prior for words over topics where $\eta_{k, v}^{(t)} = \omega_{k}^{(t)} \cdot \mathbb{E}\left[\beta_{k,v}^{(t-1)}\right] = \omega_{k}^{(t)} \cdot \frac{Cv_{k,v}^{(t-1)} + \eta_{k,v}^{(t-1)}}{\sum_{v=1}^V Cv_{k,v}^{(t-1)}}$. Because the posterior at time $t$ depends only on data at time $t$ and the state of the model at time $t-1$, tLDA models retain the Markov property.

#### Selecting the prior weight
Each $\omega_k^{(t)}$ tunes the relative weight between the base model (as prior) and new data in the posterior for each topic. This specification introduces $K$ new tuning parameters and setting $\omega_k^{(t)}$ directly is possible but not intuitive. Yet introducing a new parameter and performing some algebra collapses these $K$ tuning parameters into a single parameter with several intutive critical values. This tuning parameter, $a^{(t)}$, is related to each $\omega_k^{(t)}$ as follows:

\begin{align}
\omega_k^{(t)} &=
a^{(t)} \cdot \sum_{v = 1}^V Cv_{k,v}^{(t-1)} + \eta_{k,v}^{(t-1)}
\end{align}

Appendix 1 shows the full derivation of the relationship between $a^{(t)}$ and $\omega_k^{(t)}$.

When $a^{(t)} = 1$, fine tuning is equivalent to adding the data in $\boldsymbol{X}^{(t)}$ to $\boldsymbol{X}^{(t-1)}$. In other words, each word occurrence in $\boldsymbol{X}^{(t)}$ carries the same weight in the posterior as each word occurrence in $\boldsymbol{X}^{(t-1)}$. If $\boldsymbol{X}^{(t)}$ has more data than $\boldsymbol{X}^{(t-1)}$, then it will carry more weight. If it has less, it will carry less.

When $a^{(t)} < 1$, then the posterior has recency bias. Each word occurrence in $\boldsymbol{X}^{(t)}$ carries more weight than each word occurrence in $\boldsymbol{X}^{(t-1)}$. When When $a^{(t)} > 1$, then the posterior has precedent bias. Each word occurrence in $\boldsymbol{X}^{(t)}$ carries less weight than each word occurrence in $\boldsymbol{X}^{(t-1)}$.

Another pair of critical values are $a^{(t)} = \frac{N^{(t)}}{N^{(t-1)}}$ and $a^{(t)} = \frac{N^{(t)}}{N^{(t-1)} +\sum_{d,v} \eta_{d,v}}$, where $N^{(\cdot)} = \sum_{d,v} X^{(\cdot)}_{d,v}$. These put the total number of word occurrences in $\boldsymbol{X}^{(t)}$ and $\boldsymbol{X}^{(t-1)}$ on equal footing excluding and including $\boldsymbol\eta^{(t-1)}$, respectively. These values may be useful when comparing topical differences between a baseline group in $\boldsymbol{X}^{(t-1)}$ and "treatment" group in $\boldsymbol{X}^{(t)}$, though this use case is left to future work.

### The Algorithm
The overall tLDA algorithm proceeds in 6 steps.

1. Construct $\boldsymbol\eta^{(t)}$
2. Predict $\hat{\boldsymbol\Theta}^{(t)}$ using topics from $\hat{\boldsymbol{B}}^{(t-1)}$
3. Align vocabulary
4. Add new topics
5. Initialize $\boldsymbol{Cd}^{(t)}$ and $\boldsymbol{Cv}^{(t)}$
6. Begin Gibbs sampling with $P(z = k) = \frac{Cv_{k, n} + \eta_{k,n}}{\sum_{v=1}^V Cv_{k, v} + \eta_{k,v}} \cdot \frac{Cd_{d, k} + \alpha_k}{\left(\sum_{k=1}^K Cd_{d, k} + \alpha_k\right) - 1}$

Any real-world application of tLDA presents several practical issues which are addressed in steps 3 - 5, described in more detail below. These issues include: the vocabularies in $\boldsymbol{X}^{(t-1)}$ and $\boldsymbol{X}^{(t)}$ will not be identical; users may wish to add topics, expecting $\boldsymbol{X}^{(t)}$ to contain topics not in $\boldsymbol{X}^{(t-1)}$; and $\boldsymbol{Cd}^{(t)}$ and $\boldsymbol{Cv}^{(t)}$ should be initialized proportional to $\boldsymbol{Cd}^{(t-1)}$ and $\boldsymbol{Cv}^{(t-1)}$, respectively.

#### Aligning Vocabulary
tLDA implements an algorithm to fold in new words. This method slightly modifies the posterior probabilities in $\boldsymbol{B}^{(t-1)}$ and adds a non-zero prior by modifying $\boldsymbol\eta^{(t)}$. It involves three steps. First, append columns to $\boldsymbol{B}^{(t-1)}$ and $\boldsymbol\eta^{(t)}$ that correspond to out-of-vocabulary words. Next, set the new entries for these new words to some small value, $\epsilon > 0$ in both $\boldsymbol{B}^{(t-1)}$ and $\boldsymbol\eta^{(t)}$. Finally, re-normalize the rows of $\boldsymbol{B}^{(t-1)}$ so that they sum to one. For computational reasons, $\epsilon$ must be greater than zero. The _tidylda_ implementation chooses $\epsilon$ to the lowest decile of all values in $\boldsymbol{B}^{(t-1)}$ or $\boldsymbol\eta^{(t)}$, respectively. 

#### Adding New Topics
tLDA employs a similar method to add new, randomly initialized, topics if desired. This is achieved by appending rows to both $\boldsymbol\eta^{(t)}$ and $\boldsymbol{B}^{(t)}$, adding entries to $\boldsymbol\alpha$, and adding columns to $\boldsymbol\Theta^{(t)}$, obtained in step two above. The tLDA implementation in _tidylda_ sets the rows of $\boldsymbol\eta^{(t)}$ equal to the column means across previous topics. Then new rows of $\boldsymbol{B}^{(t)}$ are the new rows of $\boldsymbol\eta^{(t)}$ but normalized to sum to one. This effectively sets the prior for new topics equal to the average of the weighted posteriors of pre-existing topics.

The choice of setting the prior to new topics as the average of pre-existing topics is admittedly subjective. A uniform prior over words is unrealistic, being inconsistent with Zipf's law [@zipf1949]. (See also the appendix in [@jones2019coefficient].) The average over existing topics is only one viable choice. Another choice might be to choose the shape of new $\boldsymbol\eta_k$ from an estimated Zipf's coefficient of $\boldsymbol{X}^{(t)}$ and choose the magnitude by another means.

New entries to $\boldsymbol\alpha$ are initialized to be the median value of the pre-existing topics in $\boldsymbol\alpha$. Similarly, columns are appended to $\boldsymbol\Theta^{(t)}$. Entries for new topics are taken to be the median value for pre-existing topics on a per-document basis. This effectively places a uniform prior for new topics. This choice is also subjective. Other heuristic choices may be made, but it is not obvious that they would be any better or worse choices. 

#### Initializing $\boldsymbol{Cd}^{(t)}$ and $\boldsymbol{Cv}^{(t)}$
Like most other LDA implementations, tLDA initializes tokens for $\boldsymbol{Cd}^{(t)}$ and $\boldsymbol{Cv}^{(t)}$ with a single Gibbs iteration. However, instead of sampling from a uniform random for this initial step, tLDA draws a topic for the $n$-th word of the $d$-th document from the following:

\begin{align}
P(z_{d_{n}} = k) &= \hat{\boldsymbol\beta}_{k,n}^{(t)} \cdot \hat{\boldsymbol\theta}_{d,k}^{(t)}
\end{align}

After a single iteration, the number of times each topic was sampled at each document and word occurrence is counted to produce $\boldsymbol{Cd}^{(t)}$ and $\boldsymbol{Cv}^{(t)}$. After initialization where topic-word distributions are fixed, tLDA continues in a standard fashion, recalculating $\boldsymbol{Cd}^{(t)}$ and $\boldsymbol{Cv}^{(t)}$ (and therefore $P(z_{d_{n}} = k)$) at each step.

## Experiments
To evaluate tLDA, we conduct two simulation experiments and an analysis on a real-world data set. The simulation experiments evaluate the degree to which tLDA converges towards a ground truth data generating distribution. The real-world analysis constructs time series of topics from a data set of Small Business Innovation Research (SBIR) grant abstracts from 1983 to 2021.

### Simulation Analysis
Under two assumptions, tLDA should converge to stable topic estimates as it is fine tuned on more data. Specifically, (1) if $\boldsymbol{X}^{(i)}$ and $\boldsymbol{X}^{(j)}$ are generated from the same distribution, $\forall i,j \geq 0, i \neq j$, and (2) if $a \geq 1$, then tLDA should converge to stable topic estimates. However, unless a user correctly chooses $\boldsymbol\alpha$, $\boldsymbol\eta^{(0)}$, and $K$ there is no guarantee that tLDA will converge to _correct_ topic estimates. This is not a limitation of tLDA as selecting hyperparameters for any LDA model remains an open problem. Yet we hypothesize that there are heuristics one can use to get reasonably good estimates, so long as the two assumptions above hold.

To test the above, we conduct two simulation experiments. We generate topics by drawing from 128 data generating distributions. Then for each data generating distribution, we sample 100 corpora of 100 documents each. We fit a model on the first 100 documents of the data and iteratively add the remaining 100 documents at a time, fine tuning at each stage, with values of $a$ ranging from $0.2$ to $2$. The experiments are described in more detail in the below sections.

On average, models converge towards the true topics of the data generating process when values of $a$ are greater than 0.8. When values of $a$ are less than 0.8, the models tend not to converge as there is high variance between estimates. There is very high variance as to whether or not models converge when $a$ is around 0.8. Properties of the data generating process, particularly the magnitude of $\boldsymbol\alpha$, also influence whether or not the models converge. This points towards a need for more study of LDA as a data generating process of language, rather than an inherent limitation of tLDA. 

#### Synthetic Data Generation

We assume that the total vocabulary size, $V$, and number of topics, $K$, are fixed with value of $5,000$ and $25$ respectively. We further assume that $\boldsymbol\alpha$ is flat (symmetric) and that $\boldsymbol\eta$ is proportional to a power law (asymmetric) to account for Zipf's law (cite). We vary the magnitudes of $\boldsymbol\alpha$ and $\boldsymbol\eta$ and vary the number of words sampled in each context.

Specifically, we chose the following:

1. $\left(\sum_{v=1}^V \eta_v \right) \in \{50, 100, 200, 400\}$
2. $\left(\sum_{k=1}^K \alpha_k \right) \in \{0.5, 1, 3, 5\}$
3. $N_d \sim \text{Poi}(\lambda)$ where $\lambda \in \{50, 100, 200, 400\}$
4. $V = 5,000$ and $K = 25$

The above creates 64 unique sets of hyper parameters. From each, we generate two sets of population statistics, $\left\{ \boldsymbol\Theta, \boldsymbol{B} \right\}$, leaving 128 unique sets of population parameters to parametarize the generation process described in Section 1.1. From each of these sets of population parameters, $i$, we sample 100 word count matrices, $\boldsymbol{X}_i^{(t)}$, with 100 documents each.

The magnitudes of the Dirichlet hyperparameters, $\boldsymbol\eta$ and $\boldsymbol\alpha$ vary while keeping their shapes fixed. The magnitude of the parameter of a Dirichlet distribution plays a strong role in tuning the covariance between draws from that distribution. A smaller magnitude means larger variability between draws. In other words, if $\left(\sum_{v=1}^V \eta_v \right)$ is smaller, topics are less linguistically similar. If $\left(\sum_{v=1}^V \eta_v \right)$ is larger, topics are more linguistically similar. Similarly, $\left(\sum_{k=1}^K \alpha_k \right)$ tunes the topical similarity of documents.

#### Modeling Choices

We fit a total of 128,000 LDA models to the simulated data. For each of the 128 unique sets of population parameters, we sequentially fit models on 100 batches of data, using TLDA to update the parameters. We do this for 10 different settings for $a$ from $a = 0.2$ to $a = 2$ with a step size of $0.2$. This leads to 1,280 separate model chains.

In each case, the base model was fit with $K = 30$ topics, and commonly-used flat priors with $\alpha_k = 0.05$ and $\eta_v = 0.01$. The Gibbs sampler runs for 200 iterations. Posterior estimates are taken averaging over the last 50 iterations. Subsequent models are fine tuned with an additional 200 iterations with posterior estimates averaged over the last 50 and $a$ set as described above.

We fit more topics than in the population data for two reasons. First, it's unrealistic that a researcher will know the right number of topics a-priori. (In real data a true number does not even exist.) Second, fitting a fewer number of topics than is in the population would lead to a pathologically-mispecified model regardless of other choices. 

#### Evaluation Method

We base our analysis on calculations from the pairwise Hellinger distance [@hellinger1909] from the estimated topics to each of the ground truth simulated topics. For estimated topic $\hat{\boldsymbol\beta}_k^{(t)}$ and ground-truth topic $\boldsymbol\beta_{\mathfrak{k}}$, the Hellinger distance is calculated as

\begin{align}
H(\hat{\boldsymbol\beta}_k^{(t)},\boldsymbol\beta_{\mathfrak{k}}) &=
\sqrt{\frac{1}{2} 
\sum_{v=1}^V (\sqrt{\hat{\beta}_{k,v}^{(t)}} - \sqrt{\beta_{\mathfrak{k},v}}) ^ 2}
\end{align}

Note that it is not necessarily true that $k = \mathfrak{k}$ for any pair of topics. For simplicity, we denote the above $H_{k,\mathfrak{k}}^{(t)}$ and its derivative with respect to $t$ as $H_{k,\mathfrak{k}}^{'(t)}$.

From a theoretical perspective, the following should be true:
\begin{align}
& \text{If } \hat{\boldsymbol\beta}_k^{(t)} 
\text{ converges towards a stable posterior, then }
\underset{t \to \infty}{\lim} 
H_{k,\mathfrak{k}}^{'(t)} = 0 \label{eq:1} \\
& \text{If } \hat{\boldsymbol\beta}_k^{(t)} \text{ converges to }
\boldsymbol\beta_{\mathfrak{k}} \text{, then (11) holds and }
\underset{t \to \infty}{\lim}
H_{k,\mathfrak{k}}^{(t)} = 0 \label{eq:2} \\
& \text{We can compare convergence rates by finding } t \text{ such that }
H_{k,\mathfrak{k}}^{'(t)} \approx 0 \label{eq:3}
\end{align}

By extension of (\ref{eq:1}), if a whole model converges to a stable posterior, then $\underset{t \to \infty}{\lim} \sum_{k=1}^K H_{k,\mathfrak{k}}^{'(t)} = 0$. Note that converging to a stable posterior does not mean that the model converged towards the true topics of the data generating distribution. If (\ref{eq:2}) holds, then that also implies that $\hat{\boldsymbol\beta}_k^{(t)}$ is a consistent estimator of $\boldsymbol\beta_{\mathfrak{k}}$. This is unlikely to be true as an imperfect specification of $\boldsymbol\alpha$ and $\boldsymbol\eta$ mean that $H_{k,\mathfrak{k}}^{(t)}$ will always be positive. However, if $\hat{\boldsymbol\beta}_k^{(t)}$ is heading *towards* $\boldsymbol\beta_{\mathfrak{k}}$, then $H_{k,\mathfrak{k}}^{'(t)} < 0$ as it approaches its limit.

We estimate $H_{k,\mathfrak{k}}^{'(t)}$ by $H_{k,\mathfrak{k}}^{(t)} - H_{k,\mathfrak{k}}^{(t - 1)}$, normalized by $H_{k,\mathfrak{k}}^{(0)}$. Normalization allows each topic in every model to be on the same scale and allows us to chose a single threshold as being sufficiently close to zero to assess convergence or lack thereof.

Convergence is assessed in a two step process, first assessing the convergence of each estimated topic and then assessing the convergence of the model as a whole. To assess the convergence of a topic, we perform a t-test on the last 20 periods of $H_{k,\mathfrak{k}}^{'(t)}$, with a null hypothesis of the mean being unequal to zero at the 0.05 significance level. If we reject the null, we consider a topic's estimate to have converged. 

The second step corrects for multiple tests and assesses the convergence of the model as a whole. Under a hull hypothesis that we'd consider 5% of topics to have converged by random chance, we perform a binomial test. A model has converged if we reject the null that the rejection rate above is less than or equal to 5%.

Logistic regression is used to analyze which factors lead to model convergence or divergence. We use the hyperparameters that define the data generating process (described in Chapter 2) and the value of $a$ used in fine tuning that model as predictors. The outcome variable is a binary for the model having converged or not.

Whether or not the model converges towards the data generating distribution is assessed in a similar two step process. A topic converges towards the true generating distribution if the average slope of $H_{k,\mathfrak{k}}^{(t)}$ is negative, $\mathfrak{k}$ indexes the topic closest to $k$, averaging over the last. After discarding the first two periods, a t-test with a null hypothesis that the average of $H_{k,\mathfrak{k}}^{'(t)}$ from periods 3 to 100 is greater than zero. The whole model is considered to have converged towards the true data generating distribution using a binomial test, as above. Only models considered to have converged, above, are considered.

Linear regression is used to analyze which factors lead to fitted topics being closer to their matches in the true data generating distributions. We use the hyperparameters that define the data generating process (described in Chapter 2) and the value of $a$ used in fine tuning that model as predictors. The outcome variable is the hellinger distance between matched topics averaged over the last 10 periods. 

#### Findings

```{r tlda-load-libraries}
# load libraries, just in case
library(tidyverse)
# library(memisc)

# load analysis data
load("data-derived/tlda-analysis/2022-01-02-50-56/convergence-analysis.RData")
load("data-derived/tlda-analysis/2022-01-02-50-56/topic-matches.RData")
load("data-derived/tlda-analysis/2022-01-02-50-56/convergence-direction-analysis.RData")


```


Models where $a < 0.8$ almost never converge; 384 out of 385 such models diverged. Models where $a > 0.8$ tend to converge; 94% of such models converged. There is high variability in convergence where $a = 0.8$. Roughly 1/3 of the models converged when $a = 0.8$, the other 2/3 diverged. Figure [x], below, shows a box plot of p-values in the binomial test for each value of $a$. There is a clear structural break at $a = 0.8$, reflecting the clear patterns of convergence/divergence on either side of 0.8 and a high variance of convergence at 0.8.

```{r tlda-boxplot, fig.width = 6, fig.height = 4}

bin_table %>%
  ggplot(aes(x = a, y = bin_test_p)) + 
  geom_boxplot(aes(color = factor(a))) + 
  theme(legend.position = "none") + 
  ylab("P-value of Binomial test") + 
  ggtitle("Figure [x]: Structural break in convergence for a = 0.8")

```


Table 1, below, contains the results of four regression models. The models labeled "Convergence" represent logistic regression models predicting whether each of the model chains converged ($N = 1,280$). The models labeled "Direction" represent linear regression models predicting the Hellinger distance of estimated topics from converged models matched to data-generating topics, averaged over the last 20 periods and multiplied by 100 for scale ($N = 22,920$). Each of the models regresses their outcomes on $a$ and the hyperparameters of the data generating distributions with and without quadratics. Both logistic models have an in-sample accuracy of 93% and the linear models have an adjusted $R^2$ of 0.90 and 0.72 with and without quadratics, respectively. Asterisks represent the p-value associated with each coefficient: $*** \equiv p \leq 0.01$, $** \equiv  p \leq 0.05$, and $* \equiv  p \leq 0.1$.

In all cases, $a$ has the most substantial impact on the outcome. The largest determinant of whether or not a model converges is the value of $a$. As $a$ increases, the probability of a model converging also increases, albeit with decreasing returns as indicated by the decreasing quadratic. Intuitively, larger values of $a$ decrease the variance between models in a chain leading to faster convergence. Yet of the models that converge, $a$ increases the distance of the fitted topics to their matches in the data generating distribution, again with decreasing returns. In sum, if $a$ is too small, a chain of models is unlikely to converge and if $a$ is too large the chain will converge far from the true data generating topics.


```{r bin-reg-table}
# regtable <- mtable(
#   "Binomial Convergence" = bin_regression,
#   "Linear Hellinger Distance" = convergence_direction_regression,
#   summary.stats = c("N", "AIC", "R-squared")
# ) %>%
#   relabel(
#     "(Intercept)" = "Constant",
#     "a" = "a",
#     "I(a^2)" = "a Squared",
#     "doc_length" = "Avg. Doc. Length",
#     "I(doc_length^2)" = "Avg. Doc. Length Squared",
#     "beta_sum" = "Magnitude of eta",
#     "I(beta_sum^2)" = "Magnitude of eta Squared",
#     "alpha_sum" = "Magnitude of alpha",
#     "I(alpha_sum^2)" = "Magnitude of alpha Squared"
#   )

# mtable_format_latex(regtable)

# Get two more regressions
bin_regression2 <- 
  glm(
    bin_test_p <= 0.05 ~ a + I(a^2) + doc_length + I(doc_length^2) +
      beta_sum + I(beta_sum^2) + alpha_sum + I(alpha_sum^2),
    family = binomial("logit"), data = bin_table
  )

convergence_direction_regression2 <- 
  lm(
    hdist * 100 ~ a + doc_length +  
      beta_sum + alpha_sum, 
    data = match_by_avg_periods
  )

# Construct table of regression results
reg_table <- 
  broom::tidy(bin_regression) %>%
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.05 ~ "**",
    p.value < 0.1 ~ "*",
    TRUE ~ ""
  )) %>%
  select(
    Variable = term,
    Convergence = estimate,
    `Sig.` = sig
  ) %>%
  full_join(
    broom::tidy(bin_regression2) %>%
      mutate(sig = case_when(
        p.value < 0.001 ~ "***",
        p.value < 0.05 ~ "**",
        p.value < 0.1 ~ "*",
        TRUE ~ ""
      )) %>%
      select(
        Variable = term,
        Convergence = estimate,
        `Sig.` = sig
      ),
    by = c("Variable" = "Variable")
  ) %>%
  full_join(
    broom::tidy(convergence_direction_regression2) %>%
      mutate(sig = case_when(
        p.value < 0.001 ~ "***",
        p.value < 0.05 ~ "**",
        p.value < 0.1 ~ "*",
        TRUE ~ ""
      ))%>%
      select(
        Variable = term,
        Direction = estimate,
        `Sig.` = sig
      ),
    by = c("Variable" = "Variable")
  ) %>%
  full_join(
    broom::tidy(convergence_direction_regression) %>%
      mutate(sig = case_when(
        p.value < 0.001 ~ "***",
        p.value < 0.05 ~ "**",
        p.value < 0.1 ~ "*",
        TRUE ~ ""
      )) %>%
      select(
        Variable = term,
        Direction = estimate,
        `Sig.` = sig
      ),
    by = c("Variable" = "Variable")
  ) %>%
  mutate(
    Variable = case_when(
      Variable == "(Intercept)" ~ "Intercept",
      Variable == "a" ~ "$a$",
      Variable == "doc_length" ~ "Avg. Doc. Length",
      Variable == "beta_sum" ~ "$\\sum(\\boldsymbol\\eta)$",
      Variable == "alpha_sum" ~ "$\\sum(\\boldsymbol\\alpha)$",
      Variable == "I(a^2)" ~ "$a^2$",
      Variable == "I(doc_length^2)" ~ "$(\\text{Avg. Doc. Length})^2$",
      Variable == "I(beta_sum^2)" ~ "$\\sum(\\boldsymbol\\eta)^2$",
      Variable == "I(alpha_sum^2)" ~ "$\\sum(\\boldsymbol\\alpha)^2$",
    )
  ) 

options(knitr.kable.NA = '')

names(reg_table)[c(3, 5, 7, 9)] <- c("", "")

names(reg_table) <-
  names(reg_table) %>%
  str_replace_all(
    pattern = "(\\.x)|(\\.y)",
    replacement = ""
  )

knitr::kable(
  reg_table,
  digits = 2,
  caption = "Effects of $a$ and data-generating hyperparameters on convergence"
)

```

### Emperical Analysis
The simulations above examines the properties of tLDA when fine tuning is performed by adding data from the same generating distribution. While helpful for isolating effects, the real world is far messier. This section demonstrates tLDA for topic discovery on real data in a time series context.

#### Data Description

#### Modeling Choices

#### Findings

## Discussion

Note that you haven't explored adding expert input, but this could theoretically be encoded into the prior
